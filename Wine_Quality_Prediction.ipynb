{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wine Quality Prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3fiSKmR04tt",
        "outputId": "2b16a6c0-c833-4b45-a2af-669fef81d7ab"
      },
      "source": [
        "#Importing the libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from imblearn.pipeline import Pipeline\n",
        "from imblearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9FJX3Se09Rc"
      },
      "source": [
        "wine_df = pd.read_csv('winequality-red.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj8kQ4xu1BQF",
        "outputId": "d6401763-cb15-413d-9fcc-e7912bad286c"
      },
      "source": [
        "wine_df.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1599, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0RfbJVO1CSy",
        "outputId": "43109523-58a3-433a-f8ad-fa02bc397437"
      },
      "source": [
        "wine_df.columns"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
              "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
              "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es9b8PcV1D_O",
        "outputId": "e875ca47-9c7c-4cc3-e45d-33579e5ae6b0"
      },
      "source": [
        "wine_df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1599 entries, 0 to 1598\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype  \n",
            "---  ------                --------------  -----  \n",
            " 0   fixed acidity         1599 non-null   float64\n",
            " 1   volatile acidity      1599 non-null   float64\n",
            " 2   citric acid           1599 non-null   float64\n",
            " 3   residual sugar        1599 non-null   float64\n",
            " 4   chlorides             1599 non-null   float64\n",
            " 5   free sulfur dioxide   1599 non-null   float64\n",
            " 6   total sulfur dioxide  1599 non-null   float64\n",
            " 7   density               1599 non-null   float64\n",
            " 8   pH                    1599 non-null   float64\n",
            " 9   sulphates             1599 non-null   float64\n",
            " 10  alcohol               1599 non-null   float64\n",
            " 11  quality               1599 non-null   int64  \n",
            "dtypes: float64(11), int64(1)\n",
            "memory usage: 150.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "ncdQxSbU1Guz",
        "outputId": "ea102e7c-9cc5-4558-c60b-314cf036464e"
      },
      "source": [
        "wine_df.head(3)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  ...  sulphates  alcohol  quality\n",
              "0            7.4              0.70         0.00  ...       0.56      9.4        5\n",
              "1            7.8              0.88         0.00  ...       0.68      9.8        5\n",
              "2            7.8              0.76         0.04  ...       0.65      9.8        5\n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6n343WD51I_1",
        "outputId": "8494f4d4-6c88-4844-dea2-7109eab222a3"
      },
      "source": [
        "wine_df['quality'].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5    681\n",
              "6    638\n",
              "7    199\n",
              "4     53\n",
              "8     18\n",
              "3     10\n",
              "Name: quality, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "VgGhuirR1OSH",
        "outputId": "ef5912e9-3bc9-403f-f69a-ccef7e1391d2"
      },
      "source": [
        "sns.countplot(wine_df['quality'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f61301fbc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mbEH06K1PFy"
      },
      "source": [
        "# Creating new dependent feature - quality_c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsHQpRzj1bT1"
      },
      "source": [
        "If score is 7 and above, it will be a good wine. \n",
        "Else, it will be a bad wine.\n",
        "\n",
        "0 - bad wine \n",
        "\n",
        "1- good wine"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QBm2lAC1YOq"
      },
      "source": [
        "def get_bin(wine_df: pd.DataFrame) -> pd.DataFrame:\n",
        " \n",
        "    bins = [-np.inf, 6.5, np.inf]\n",
        "    group_names = [0, 1]\n",
        "    wine_df['quality_c'] = pd.cut(wine_df['quality'], bins = bins, labels = group_names)\n",
        "    wine_df.drop('quality', axis=1, inplace=True)\n",
        "    return wine_df\n",
        "\n",
        "wine_df = get_bin(wine_df)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "8WxrYpEj1nz-",
        "outputId": "72f4f6dc-3c99-4105-c0ee-fe7796f73aef"
      },
      "source": [
        "sns.countplot(wine_df['quality_c'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f612aad3190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGJP8oaS6fZV",
        "outputId": "3ed8aedf-a69b-41dd-8829-fd5d6127fdbf"
      },
      "source": [
        "print(\"counts of bad wine in data:\", wine_df['quality_c'].value_counts()[0])\n",
        "print(\"counts of good wine in data:\", wine_df['quality_c'].value_counts()[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counts of bad wine in data: 1382\n",
            "counts of good wine in data: 217\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNQnK7TF1soF",
        "outputId": "4d5cb90c-1a23-454a-e6f5-9343bbc3664c"
      },
      "source": [
        "print(\"percentage of bad wine in data:\", len(wine_df[wine_df['quality_c']==0])/len(wine_df))\n",
        "print(\"percentage of good wine in data:\", len(wine_df[wine_df['quality_c']==1])/len(wine_df))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "percentage of bad wine in data: 0.8642901813633521\n",
            "percentage of good wine in data: 0.1357098186366479\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMtOaF1D2O_p"
      },
      "source": [
        "we can see that this is a case of imbalance dataset, as we have a lot more bad wines in the data, than good wine. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBmhHdIC3EyE"
      },
      "source": [
        "It will not be a good idea to do under samping, as our dataset is small enough. \n",
        "\n",
        "Under sampling will essential reduce and give up info, causing our model to learn from even fewer data. \n",
        "\n",
        "\"The undersampling method is conducted by removing some random examples from the majority class, at cost of some information in the original data are removed as well.\" (credit: https://towardsdatascience.com/imbalanced-classification-in-python-smote-tomek-links-method-6e48dfe69bbc)\n",
        "\n",
        "Eg. output of under sampling can be \n",
        "\n",
        "0 - 217\n",
        "\n",
        "1 - 217\n",
        "\n",
        "we are throwing away 1k plus of data (for bad wines)\n",
        "\n",
        "we will try to do over sampling here. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cKCPT353YPU"
      },
      "source": [
        "# Model without any over sampling..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKULfNef30IZ"
      },
      "source": [
        "i will try to run a baseline model to see the results BEFORE we apply any over sampling techniques\n",
        "\n",
        "also, when it comes to imbalance dataset, it might be misleading to look at the accuracy score. \n",
        "\n",
        "we should focus more on F1, or minority class predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxPhy7Dw4xPV"
      },
      "source": [
        "#preparing our X and y before train test split for baseline model...\n",
        "columns = wine_df.columns.tolist()\n",
        "columns = [c for c in columns if c not in [\"quality_c\"]]\n",
        "target = \"quality_c\"\n",
        "\n",
        "X = wine_df[columns]\n",
        "y = wine_df[target]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "611tkQbI4rFA"
      },
      "source": [
        "#train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IS9Wr2_O8NU"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "model = LogisticRegression()\n",
        "steps = [('scale', scaler), ('model', model)]\n",
        "pipeline = Pipeline(steps=steps)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt2SJE-i3zkn"
      },
      "source": [
        "#cv = KFold(n_splits = 5, random_state=None, shuffle=False)\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "grid_param = {'model__C':10.0 **np.arange(-2,3), 'model__penalty':['l1','l2']}\n",
        "\n",
        "log_clf = GridSearchCV(estimator = pipeline, param_grid = grid_param, cv = cv, n_jobs=-1, scoring='f1_macro', verbose=10)\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6by9tTPxxw9"
      },
      "source": [
        "use three repeats of 10-fold cross-validation, meaning that 10-fold cross-validation is applied three times fitting and evaluating 30 models on the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZPWQBOz6jvx",
        "outputId": "6ff65a95-189e-4543-cda2-bc7169b9a7dd"
      },
      "source": [
        "log_clf.fit(X_train,y_train)\n",
        "\n",
        "y_pred = log_clf.predict(X_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    1.3s\n",
            "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1975s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0367s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0647s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1960s.) Setting batch_size=16.\n",
            "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=-1)]: Done 267 tasks      | elapsed:    3.5s\n",
            "[Parallel(n_jobs=-1)]: Done 293 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    3.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PU7krJf76jtu",
        "outputId": "c5e77687-223c-4f33-aecd-ea15dc6f69e7"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[267   7]\n",
            " [ 35  11]]\n",
            "0.86875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.93       274\n",
            "           1       0.61      0.24      0.34        46\n",
            "\n",
            "    accuracy                           0.87       320\n",
            "   macro avg       0.75      0.61      0.64       320\n",
            "weighted avg       0.84      0.87      0.84       320\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20Fm9vPM8lqo"
      },
      "source": [
        "without doing any over sampling...  \n",
        "\n",
        "we are getting accuracy of 87%, which is pretty decent. \n",
        "\n",
        "but bear in mind, we should not only look at accuracy score for imbalanced dataset\n",
        "\n",
        "**Zooming into our good wine prediction (class = 1) which had 46 of them in the test data. **\n",
        "\n",
        "precision is 0.61, which means among our good wine predictions, only 61% are correct. \n",
        "\n",
        "recall is 0.24, meaning out of all the real good wines, our model only picked up and recognised and classified 24% successfully. aka we see 11 among 45 real good wines are classified successfully. \n",
        "\n",
        "In other words, the model is struggling to correctly predict the minority aka good wines. perhaps by introducing more good wines data into training dataset, the model will learn about good wines better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMwVaAH06jru"
      },
      "source": [
        "# Method 1 - RandomOverSampler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXa6gjZh-SbY"
      },
      "source": [
        "Random Oversampling: Randomly duplicate examples in the minority class, which involves randomly selecting examples from the minority class, with replacement, and adding them to the training dataset.\n",
        "\n",
        "In the vanilla oversampling method, the idea is to duplicate some random examples from the minority class — thus this technique does not add any new information from the data. (credit: https://towardsdatascience.com/imbalanced-classification-in-python-smote-tomek-links-method-6e48dfe69bbc)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PpL2dEu-Key"
      },
      "source": [
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from collections import Counter"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSUMYmp2-eua",
        "outputId": "a618f210-498e-4c2a-dcdc-78f9d378d17b"
      },
      "source": [
        "os=RandomOverSampler(0.8)\n",
        "X_train_os, y_train_os = os.fit_sample(X_train,y_train)\n",
        "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
        "\n",
        "print(\"The number of classes after fit {}\".format(Counter(y_train_os)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of classes before fit Counter({0: 1108, 1: 171})\n",
            "The number of classes after fit Counter({0: 1108, 1: 886})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZDI8V2C-4Cm"
      },
      "source": [
        "now, we can see that our good wines counts increase from 171 to 886 for our training dataset. \n",
        "\n",
        "good wines (886) are now 80% of our bad wines (1108) for training data. \n",
        "\n",
        "Note: test data is not modified in any ways to preserve its integrity\n",
        "\n",
        "now, let's re-train our model again with new training data..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLIZLJgeR1S3"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "model = LogisticRegression()\n",
        "steps = [('scale', scaler), ('model', model)]\n",
        "pipeline = Pipeline(steps=steps)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L99cLfMC-xbw",
        "outputId": "2fccb4b9-18da-41f1-f3da-190767770a08"
      },
      "source": [
        "grid_param = {'model__C':10.0 **np.arange(-2,3), 'model__penalty':['l1','l2']}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "log_clf = GridSearchCV(estimator = pipeline, param_grid = grid_param, cv = cv, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
        "\n",
        "log_clf.fit(X_train_os, y_train_os)\n",
        "\n",
        "y_pred = log_clf.predict(X_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0093s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0207s.) Setting batch_size=4.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0355s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1192s.) Setting batch_size=16.\n",
            "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1930s.) Setting batch_size=32.\n",
            "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:    1.0s\n",
            "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed:    1.5s\n",
            "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    2.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1-N8PCv_3zr",
        "outputId": "2becd701-9036-4483-bf02-a11ac09d2af1"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[229  45]\n",
            " [ 12  34]]\n",
            "0.821875\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.84      0.89       274\n",
            "           1       0.43      0.74      0.54        46\n",
            "\n",
            "    accuracy                           0.82       320\n",
            "   macro avg       0.69      0.79      0.72       320\n",
            "weighted avg       0.88      0.82      0.84       320\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcwzR9s2_7Ji"
      },
      "source": [
        "after doing random over sampling...\n",
        "\n",
        "we are getting overall accuracy score of 82%, still decent but it has dropped from 87% (pre over sampling)\n",
        "\n",
        "**Zooming into our good wine predictions (class = 1), which had 46 of them in the test data...**\n",
        "\n",
        "precision = 0.43, which means among our good wine predictions, only 43% are correct. \n",
        "\n",
        "recall is 0.74 (this is a huge improvement from pre sampling which was around 20%. meaning out of all the real good wines, our model is now able to pick up and recognise and classify 74% of them successfully. aka we see 34 among 46 real good wines are classified successfully. \n",
        "\n",
        "The trade off? \n",
        "\n",
        "looking at our bad wine predictions (class = 0), we see recall dropped from 0.97 -> 0.84\n",
        "\n",
        "this means that our model becomes a little worse at recognising the bad wines. Out of all the 274 bad wines in test dataset, our model is only able to recognise 229 of them and classify them as bad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsmag_3HA4ak"
      },
      "source": [
        "# Method 2a - SMOTE + Tomek Links"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC1HlV5EF0i6"
      },
      "source": [
        "Synthetic Minority Oversampling Technique\n",
        "\n",
        "\n",
        "Unlike random oversampling that only duplicates some random examples from the minority class, **SMOTE generates examples based on the distance of each data (usually using Euclidean distance) and the minority class nearest neighbors, so the generated examples are different from the original minority class.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAo33Tb5GLd6"
      },
      "source": [
        "This method is effective because the synthetic data that are generated are relatively close with the feature space on the minority class, **thus adding new “information” on the data, unlike the original oversampling method.***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4pVtngCMBxy"
      },
      "source": [
        "Tomek Links\n",
        "\n",
        "This method can be used to find desired samples of data from the majority class that is having the lowest Euclidean distance with the minority class data (i.e. the data from the majority class that is closest with the minority class data, thus make it ambiguous to distinct).\n",
        "\n",
        "Hence, the majority of class observations from these links are removed as it is believed to increase the class separation near the decision boundaries.\n",
        "\n",
        "This hybridization techniques involve combining both undersampling and oversampling techniques."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF3OabxaE6zv"
      },
      "source": [
        "from imblearn.combine import SMOTETomek"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OVwuFlcFJCT",
        "outputId": "89e4baee-effd-4ec5-ea31-d41fc4d4cdf9"
      },
      "source": [
        "os = SMOTETomek()\n",
        "X_train_sm, y_train_sm =os.fit_sample(X_train,y_train)\n",
        "\n",
        "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
        "\n",
        "print(\"The number of classes after fit {}\".format(Counter(y_train_sm)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of classes before fit Counter({0: 1108, 1: 171})\n",
            "The number of classes after fit Counter({0: 1100, 1: 1100})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjV7TeLJ96dB"
      },
      "source": [
        "after applying SMOTE + Tomek links which essentially increase counts of minority and decrease counts of majority, the final training dataset is \n",
        "\n",
        "0 - 1100\n",
        "\n",
        "1 - 1100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6aijENKSiTa"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "model = LogisticRegression()\n",
        "steps = [('scale', scaler), ('model', model)]\n",
        "pipeline = Pipeline(steps=steps)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LixNH0RKN7vU",
        "outputId": "8b14aa94-9929-4a52-ff82-5d04a9c88299"
      },
      "source": [
        "grid_param = {'model__C':10.0 **np.arange(-2,3), 'model__penalty':['l1','l2']}\n",
        "\n",
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "log_clf = GridSearchCV(estimator = pipeline, param_grid = grid_param, cv = cv, n_jobs=-1, scoring='f1_macro',verbose=10)\n",
        "\n",
        "log_clf.fit(X_train_sm, y_train_sm)\n",
        "\n",
        "y_pred = log_clf.predict(X_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0073s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0337s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0284s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1469s.) Setting batch_size=16.\n",
            "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done 140 tasks      | elapsed:    0.9s\n",
            "[Parallel(n_jobs=-1)]: Done 252 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done 276 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    2.1s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geNxRyjuNyNp",
        "outputId": "cf1dd8bc-e136-47e6-87aa-f3075a4f72a0"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[223  51]\n",
            " [  9  37]]\n",
            "0.8125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.81      0.88       274\n",
            "           1       0.42      0.80      0.55        46\n",
            "\n",
            "    accuracy                           0.81       320\n",
            "   macro avg       0.69      0.81      0.72       320\n",
            "weighted avg       0.88      0.81      0.83       320\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9_CoWBYNyLW"
      },
      "source": [
        "after applying SMOTE + TOmek, things look even better for our minority class predictions\n",
        "\n",
        "we are getting overall accuracy of 81%, almost equal as random over sampling. \n",
        "\n",
        "***Zooming into our good wine prediction (class = 1)...***\n",
        "\n",
        "precision = 0.42 which means among all the good wine prediction, only 42% are correct. this is almost same as random over sampling.\n",
        "\n",
        "recall = 0.80. this is a 6% improvement from random over sampling which was 0.74. meaning out of all the real good wines, our model is now able to pick up and recognise and classify 80% of them successfully aka we see 37 among 46 good wines are classfied successfully.\n",
        "\n",
        "***Now, let's also look at bad wine predictions to see if there's any trade off...\"***\n",
        "\n",
        "precision for bad wine: 0.96, that's almost same as random over sampling. \n",
        "\n",
        "recall - slight drop from 0.84 -> 0.81 as compared with random over sampling. Out of 274 bad wines in test dataset, our model could recognise and classify 223 of them as bad wines correctly. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxIfpZ0dNyJk"
      },
      "source": [
        "# Method 2b - SMOTE with random under sampling of majority class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4B5FfJQQz1t"
      },
      "source": [
        "for this method 2b, we are doing 2 things in a pipeline. \n",
        "\n",
        "1. SMOTE. \n",
        "\n",
        "\n",
        "2. under sampling of the majority class aka bad wines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acjURn2bNyHJ"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "model = LogisticRegression()\n",
        "over = SMOTE(sampling_strategy=0.7)\n",
        "under = RandomUnderSampler(sampling_strategy=0.8)\n",
        "steps = [('scale', scaler), ('over', over), ('under', under), ('model', model)]\n",
        "pipeline = Pipeline(steps=steps)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqrIJJkCRRQ1"
      },
      "source": [
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "grid_param_p = {'model__C':10.0 **np.arange(-2,3),'model__penalty':['l1','l2']}\n",
        "\n",
        "cv = KFold(n_splits = 5, random_state=None, shuffle=False)\n",
        "\n",
        "log_clf = GridSearchCV(estimator = pipeline, param_grid = grid_param_p, cv = cv, n_jobs=-1, scoring='f1_macro', verbose=10)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrXZWtwLRfj7",
        "outputId": "1e08f0a7-d8b3-4489-a094-630ad5c1a509"
      },
      "source": [
        "log_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = log_clf.predict(X_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0670s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0837s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1423s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h75DQztQr4OL",
        "outputId": "385cce9c-a5c9-4014-c1c5-2055317fa8d4"
      },
      "source": [
        "log_clf.best_params_"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model__C': 1.0, 'model__penalty': 'l2'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7juwEXm1Rrb5",
        "outputId": "8302caa4-f464-4d70-a4da-d9b19894deeb"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[227  47]\n",
            " [ 13  33]]\n",
            "0.8125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.83      0.88       274\n",
            "           1       0.41      0.72      0.52        46\n",
            "\n",
            "    accuracy                           0.81       320\n",
            "   macro avg       0.68      0.77      0.70       320\n",
            "weighted avg       0.87      0.81      0.83       320\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CD5jYfpLAkw6"
      },
      "source": [
        "what we did here was that increasing minority, and then decreasing majority. \n",
        "\n",
        "over = SMOTE(sampling_strategy=0.7)\n",
        "\n",
        "under = RandomUnderSampler(sampling_strategy=0.8)\n",
        "\n",
        "raw train data \n",
        "\n",
        "{0: 1108, 1: 171}\n",
        "\n",
        "after SMOTE\n",
        "\n",
        "{0: 1108, 1: 775}\n",
        "\n",
        "after SMOTE and random under sampling\n",
        "\n",
        "{0: 968, 1: 775}\n",
        "\n",
        "overall, not much improvement observed from this method.\n",
        "\n",
        "overall accuracy is 0.81, same as SMOTE\n",
        "\n",
        "minority prediction (good wine) is worse off, as now recall is 0.72. model is only able to classify 33/45 good wines in test dataset.\n",
        "\n",
        "majority class performance looks same - F1 score = 0.88\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPGMpSOikiTI",
        "outputId": "5998f2f0-ebe7-431a-bb54-0ad2d934aa89"
      },
      "source": [
        "# over = SMOTE(sampling_strategy=0.7)\n",
        "\n",
        "# X_train_ov, y_train_ov =over.fit_sample(X_train,y_train)\n",
        "\n",
        "# print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
        "\n",
        "# print(\"The number of classes after fit {}\".format(Counter(y_train_ov)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of classes before fit Counter({0: 1108, 1: 171})\n",
            "The number of classes after fit Counter({0: 1108, 1: 775})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wm564eF-lG6P",
        "outputId": "ec3dc2ea-38ef-4c37-ec90-632ba326f49b"
      },
      "source": [
        "# under = RandomUnderSampler(sampling_strategy=0.8)\n",
        "\n",
        "# X_train_ovu, y_train_ovu =under.fit_sample(X_train_ov, y_train_ov)\n",
        "\n",
        "# print(\"The number of classes before fit {}\".format(Counter(y_train_ov)))\n",
        "\n",
        "# print(\"The number of classes after fit {}\".format(Counter(y_train_ovu)))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of classes before fit Counter({0: 1108, 1: 775})\n",
            "The number of classes after fit Counter({0: 968, 1: 775})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRngVQyYuJsP"
      },
      "source": [
        "# Method 3 - ADASYN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eV8AJDsM5scn"
      },
      "source": [
        "Adaptive Synthetic Sampling Approach\n",
        "\n",
        "The essential idea of ADASYN is to produce an appropriate number of synthetic alternatives for each observation belonging to the minority class. The concept of “appropriate number” here depends on how hard it is to learn the original observation. In particular, an observation from the minority class is “hard to learn” if many examples from the majority class with features similar to that observation exist\n",
        "\n",
        "(credit: https://medium.com/quantyca/oversampling-and-undersampling-adasyn-vs-enn-60828a58db39)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "py97UmoDuJqC"
      },
      "source": [
        "from imblearn.over_sampling import ADASYN"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thHjJ7rLuMYh",
        "outputId": "58d4c7e4-4665-499e-ab2d-7a33b88327c1"
      },
      "source": [
        "ada = ADASYN(random_state=42)\n",
        "X_train_ada, y_train_ada =ada.fit_sample(X_train,y_train)\n",
        "\n",
        "print(\"The number of classes before fit {}\".format(Counter(y_train)))\n",
        "\n",
        "print(\"The number of classes after fit {}\".format(Counter(y_train_ada)))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of classes before fit Counter({0: 1108, 1: 171})\n",
            "The number of classes after fit Counter({0: 1108, 1: 1095})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCLspkVbVosp"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "model = LogisticRegression()\n",
        "steps = [('scale', scaler), ('model', model)]\n",
        "pipeline = Pipeline(steps=steps)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpmgekI1uYSZ",
        "outputId": "9ca9e799-54a7-4ca7-8921-b9918c967ea8"
      },
      "source": [
        "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
        "\n",
        "grid_param = {'model__C':10.0 **np.arange(-2,3),'model__penalty':['l1','l2']}\n",
        "\n",
        "log_clf = GridSearchCV(estimator = pipeline, param_grid = grid_param, cv = cv, n_jobs=-1, scoring='f1_macro', verbose=10)\n",
        "\n",
        "log_clf.fit(X_train_ada, y_train_ada)\n",
        "\n",
        "y_pred = log_clf.predict(X_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 30 folds for each of 10 candidates, totalling 300 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0097s.) Setting batch_size=2.\n",
            "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0283s.) Setting batch_size=4.\n",
            "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.0294s.) Setting batch_size=8.\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1657s.) Setting batch_size=16.\n",
            "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Batch computation too fast (0.1533s.) Setting batch_size=32.\n",
            "[Parallel(n_jobs=-1)]: Done 156 tasks      | elapsed:    1.1s\n",
            "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed:    1.6s\n",
            "[Parallel(n_jobs=-1)]: Done 248 tasks      | elapsed:    1.9s\n",
            "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:    2.2s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YHjwQUyusgL",
        "outputId": "7c764c5e-8da0-466c-c543-edd557b193b4"
      },
      "source": [
        "print(confusion_matrix(y_test,y_pred))\n",
        "print(accuracy_score(y_test,y_pred))\n",
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[220  54]\n",
            " [  9  37]]\n",
            "0.803125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.80      0.87       274\n",
            "           1       0.41      0.80      0.54        46\n",
            "\n",
            "    accuracy                           0.80       320\n",
            "   macro avg       0.68      0.80      0.71       320\n",
            "weighted avg       0.88      0.80      0.83       320\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ve0YGDcewSXR"
      },
      "source": [
        "after applying ADASYN method, overall accuracy is now 80%, not much differ from SMOTE or random over sampling method.\n",
        "\n",
        "***Zooming into our good wine prediction (class = 1)...***\n",
        "\n",
        "precision is 0.41 which means among all the good wine predictions, 41% are correct. nothing much improvement in terms of precision. Pretty much same as random over sampling and SMOTE. \n",
        "\n",
        "recall wise, we can see that recall for good wines is now 0.80%. this is an improvement from SMOTE, with 37/46 good wines correctly classfied in the test dataset. \n",
        "\n",
        "our model is now able to recognised and correctly identify the good wines in the test dataset . \n",
        "\n",
        "***Now, let's look at bad wine prediction to see if there's any trade off...***\n",
        "\n",
        "precision for bad wine is 0.96, that's a tie with other methods. \n",
        "\n",
        "recall for bad wine is 0.80, slightly worse off SMOTE as now model can recognise 220 bad wines among 274 bad wines in the test dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuxiC55KXShY"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pruBPdOiXVuZ"
      },
      "source": [
        "ADASYN seems to be able to populate samples which allow our model to train better and learn better on the minority class aka good wines, hence producing better results at identify good wines in the test dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCopS_Y6XVsg"
      },
      "source": [
        "We can also see that generally there's a trade off between performance for predicting good and bad wines. \n",
        "\n",
        "Eg. when the model learns better at predicting good wines, they will do worse at predicting bad wines.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2JBuy7Wglft"
      },
      "source": [
        "# Future enhancement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7L21Qc4gnXm"
      },
      "source": [
        "\n",
        "\n",
        "1.   try out with different models. Tree ensemble models might do even better\n",
        "2.   work with much larger dataset like credit card frauds, this will likely show drastic improvements when we do sampling methods when we predict the fraud cases (minority)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrBznUC3g5Pw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}